{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#basic imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#metrics, model selection tools, scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#natural language processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "\n",
    "#other\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df = pd.read_csv(\"msk-redefining-cancer-treatment/training_variants\", index_col = 0)\n",
    "test_variants_df = pd.read_csv(\"msk-redefining-cancer-treatment/test_variants\", header = None, names = train_variants_df.columns, index_col = 0)\n",
    "train_text_df = pd.read_csv(\"msk-redefining-cancer-treatment/training_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"], index_col = 0)\n",
    "test_text_df = pd.read_csv(\"msk-redefining-cancer-treatment/test_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"], index_col = 0)\n",
    "train_variants_df = train_variants_df.merge(train_text_df, left_index = True, right_index = True)\n",
    "test_variants_df = test_variants_df.merge(test_text_df, left_index = True, right_index = True)\n",
    "#5 observations, all different genes, missing text information\n",
    "train_variants_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "We are creating as simple of a model possible to see what we can predict just from knowing hte Gene and the Variation. We will not use 'Text' nor do anything with the 'Variation' column, as this would require deliberate and consequential feature engineering choices.\n",
    "\n",
    "We will use this as a benchmark to evaluate our models later. As baseline model classifiers, we will use logisitic regression, as it is well-suited to multiclass classification, and random forest, as it is a versatile and powerful ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df = train_variants_df.dropna() # only a handful, so ok to drop\n",
    "baseline_y = train_variants_df.Class\n",
    "baseline_X = train_variants_df.drop(columns = ['Text', 'Class'])\n",
    "baseline_X = pd.get_dummies(baseline_X)\n",
    "base_X_train, base_X_test, base_y_train, base_y_test = train_test_split(baseline_X, baseline_y, \\\n",
    "                                                                        test_size = .2, shuffle = True,\\\n",
    "                                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5662650602409639"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "model_l = logisticRegr.fit(base_X_train, base_y_train)\n",
    "base_l_score = model_l.score(base_X_test, base_y_test)\n",
    "base_l_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5737951807228916"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 50)\n",
    "model_rf = rf.fit(base_X_train, base_y_train)\n",
    "base_rf_score = model_rf.score(base_X_test, base_y_test)\n",
    "base_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two classifiers' models hover around an accuracy of 57%.\n",
    "\n",
    "This already is a substantial improvement over random (11.11%) \n",
    "or than if we chose the largest class (28%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Background Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidic_polar = {'D': 'Aspartic Acid', 'E': 'Glutamic Acid'}\n",
    "basic_polar = {'R': 'Arginine', 'H': 'Histidine', 'K': 'Lysine'}\n",
    "nonpolar = {'A': 'Alanine', 'C': 'Cysteine', 'G': 'Glycine', 'I': 'Isoleucine', 'L': 'Leucine', 'M': 'Methionine',\\\n",
    "           'F': 'Phenylalanine', 'P': 'Proline', 'W': 'Tryptophan', 'V': 'Valine'}\n",
    "polar = {'N': 'Asparagine', 'Q': 'Glutamine', 'S': 'Serine', 'T': 'Threonine', 'Y': 'Tyrosine'}\n",
    "\n",
    "amino_acids = [acidic_polar, basic_polar, nonpolar, polar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_type(variation):\n",
    "    if 'Truncating Mutations' in variation or 'trunc' in variation:\n",
    "        mutation = 'Nonsense'\n",
    "    elif 'delins' in variation.lower():\n",
    "        mutation = 'Deletion/Insertion'\n",
    "    elif 'ins' in variation.lower():\n",
    "        mutation = 'Insertion'\n",
    "    elif 'fs' in variation.lower():\n",
    "        mutation = 'Frameshift'\n",
    "    elif 'del' in variation.lower():\n",
    "        mutation = 'Deletion'\n",
    "    elif 'dup' in variation.lower():\n",
    "        mutation = 'Duplication'\n",
    "    elif 'splice' in variation.lower():\n",
    "        mutation = 'Splice'\n",
    "    elif (variation == 'Deletion') or (variation == 'Amplification') or (variation == 'Fusions') or (variation == 'Overexpression'):\n",
    "        mutation = variation\n",
    "    elif '*' in variation.lower():\n",
    "            mutation = 'Nonsense'\n",
    "    elif len(variation) <= 6:\n",
    "        mutation = 'Non-Conservative Missense'\n",
    "        #mutation = variation[0] #+ variation[-1]\n",
    "        for amino_acid in amino_acids:\n",
    "            if (variation[0] in amino_acid) and (variation[-1] in amino_acid):\n",
    "                mutation = 'Conservative Missense'\n",
    "    elif 'Fusion' in variation:\n",
    "        mutation = 'Fusions'\n",
    "    elif 'prom' in variation.lower():\n",
    "        mutation = 'Promoter'\n",
    "    else:\n",
    "        mutation = 'Other'\n",
    "    return mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokenizer(str_input):\n",
    "    mod = re.sub(\"\\d\", \"\", str_input)\n",
    "    words = re.sub(\"\\W\", \" \", mod).lower().split()\n",
    "    words = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_texts(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    resultwords  = [word for word in re.split(\"\\W+\", text) \\\n",
    "                    if lemmatizer.lemmatize(word.lower()) in top_words]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Final Cleaning of Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gene             Variation  Class  \\\n",
       "ID                                        \n",
       "0   FAM58A  Truncating Mutations      1   \n",
       "1      CBL                 W802*      2   \n",
       "2      CBL                 Q249E      2   \n",
       "3      CBL                 N454D      3   \n",
       "4      CBL                 L399V      4   \n",
       "\n",
       "                                                 Text  \n",
       "ID                                                     \n",
       "0   Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1    Abstract Background  Non-small cell lung canc...  \n",
       "2    Abstract Background  Non-small cell lung canc...  \n",
       "3   Recent evidence has demonstrated that acquired...  \n",
       "4   Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_variants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_exploration = train_variants_df[['Class','Text']].groupby(['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer(stop_words = 'english', tokenizer = lemmatize_tokenizer, encoding = 'latin-1',\\\n",
    "                         min_df = .25, max_features = 10000, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_dfs = []\n",
    "top_words = set()\n",
    "for name, group in text_exploration:\n",
    "    features = counter.fit_transform(group.Text).toarray()\n",
    "    feature_names = counter.get_feature_names()\n",
    "    top_words = top_words.union(set(feature_names))\n",
    "    top_words_dfs.append(pd.DataFrame(features, columns = feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2918"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df.Text = train_variants_df.Text.apply(edit_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyclin dependent kinases regulate variety fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background Non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background Non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated acquired nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations B lineage lymphoma Cbl gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gene             Variation  Class  \\\n",
       "ID                                        \n",
       "0   FAM58A  Truncating Mutations      1   \n",
       "1      CBL                 W802*      2   \n",
       "2      CBL                 Q249E      2   \n",
       "3      CBL                 N454D      3   \n",
       "4      CBL                 L399V      4   \n",
       "\n",
       "                                                 Text  \n",
       "ID                                                     \n",
       "0   Cyclin dependent kinases regulate variety fund...  \n",
       "1   Abstract Background Non small cell lung cancer...  \n",
       "2   Abstract Background Non small cell lung cancer...  \n",
       "3   Recent evidence has demonstrated acquired nove...  \n",
       "4   Oncogenic mutations B lineage lymphoma Cbl gen...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_variants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df['Label'] = 'Train'\n",
    "test_variants_df['Label'] = 'Test'\n",
    "concat_df = pd.concat([train_variants_df.dropna(), test_variants_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['Mutation Type'] = concat_df.Variation.apply(get_mutation_type)\n",
    "concat_df.reset_index(inplace = True, drop = True)\n",
    "concat_df = pd.get_dummies(concat_df, columns = ['Gene', 'Mutation Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_counter =  CountVectorizer(stop_words = 'english',\\\n",
    "                         tokenizer = lemmatize_tokenizer, encoding = 'latin-1',\\\n",
    "                         max_df = .25, max_features = 20000, ngram_range = (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_counter.fit_transform(concat_df['Text']).toarray()\n",
    "cleaned_df = pd.DataFrame(features, columns = final_counter.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_egfr_</th>\n",
       "      <th>a_yinsfqea</th>\n",
       "      <th>aa</th>\n",
       "      <th>aa aa</th>\n",
       "      <th>aacr</th>\n",
       "      <th>aacrjournals</th>\n",
       "      <th>aacrjournals org</th>\n",
       "      <th>aacrjournals org american</th>\n",
       "      <th>aacrjournals org american association</th>\n",
       "      <th>aacrjournals org cancer</th>\n",
       "      <th>...</th>\n",
       "      <th>Mutation Type_Deletion/Insertion</th>\n",
       "      <th>Mutation Type_Duplication</th>\n",
       "      <th>Mutation Type_Frameshift</th>\n",
       "      <th>Mutation Type_Fusions</th>\n",
       "      <th>Mutation Type_Insertion</th>\n",
       "      <th>Mutation Type_Non-Conservative Missense</th>\n",
       "      <th>Mutation Type_Nonsense</th>\n",
       "      <th>Mutation Type_Overexpression</th>\n",
       "      <th>Mutation Type_Promoter</th>\n",
       "      <th>Mutation Type_Splice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _egfr_  a_yinsfqea  aa  aa aa  aacr  aacrjournals  aacrjournals org  \\\n",
       "0       0           0   0      0     0             0                 0   \n",
       "1       0           0   0      0     0             0                 0   \n",
       "2       0           0   0      0     0             0                 0   \n",
       "3       0           0   0      0     0             0                 0   \n",
       "4       0           0   0      0     0             0                 0   \n",
       "\n",
       "   aacrjournals org american  aacrjournals org american association  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   aacrjournals org cancer  ...  Mutation Type_Deletion/Insertion  \\\n",
       "0                        0  ...                                 0   \n",
       "1                        0  ...                                 0   \n",
       "2                        0  ...                                 0   \n",
       "3                        0  ...                                 0   \n",
       "4                        0  ...                                 0   \n",
       "\n",
       "   Mutation Type_Duplication  Mutation Type_Frameshift  Mutation Type_Fusions  \\\n",
       "0                          0                         0                      0   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      0   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         0                      0   \n",
       "\n",
       "   Mutation Type_Insertion  Mutation Type_Non-Conservative Missense  \\\n",
       "0                        0                                        0   \n",
       "1                        0                                        0   \n",
       "2                        0                                        1   \n",
       "3                        0                                        1   \n",
       "4                        0                                        0   \n",
       "\n",
       "   Mutation Type_Nonsense  Mutation Type_Overexpression  \\\n",
       "0                       1                             0   \n",
       "1                       1                             0   \n",
       "2                       0                             0   \n",
       "3                       0                             0   \n",
       "4                       0                             0   \n",
       "\n",
       "   Mutation Type_Promoter  Mutation Type_Splice  \n",
       "0                       0                     0  \n",
       "1                       0                     0  \n",
       "2                       0                     0  \n",
       "3                       0                     0  \n",
       "4                       0                     0  \n",
       "\n",
       "[5 rows x 20284 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df = cleaned_df.merge(concat_df, left_index = True, right_index = True)\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training and Testing Sets for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df = concat_df[concat_df['Label'] == 'Train']\n",
    "test_variants_df = concat_df[concat_df['Label'] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_variants_df.Class\n",
    "X_train = train_variants_df.drop(columns = ['Variation', 'Class', 'Text', 'Label'])\n",
    "\n",
    "y_test = test_variants_df.Class\n",
    "X_test = test_variants_df.drop(columns = ['Variation', 'Class', 'Text', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3299, 20280) \n",
      "X_test shape: (365, 20280)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape} \\nX_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation using stratified Kfolds\n",
    "cv = StratifiedKFold(n_splits=10, random_state= 42, shuffle = True)\n",
    "\n",
    "# set up dictionary to capture results\n",
    "results = {}\n",
    "results['Baseline Logistic Regression'] = [base_l_score, np.nan]\n",
    "results['Baseline Random Forest'] = [base_rf_score, np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "log_random = RandomizedSearchCV(logisticRegr, hyperparameters, cv=cv, random_state = 1, n_iter = 20)\n",
    "best_logistic_model = log_random.fit(X_train, y_train)\n",
    "\n",
    "i = np.where(best_logistic_model.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "mean = best_logistic_model.cv_results_['mean_test_score'][i]\n",
    "std = best_logistic_model.cv_results_['std_test_score'][i]\n",
    "results['Logistic Regression'] = [mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.2530940677291005, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logistic_model.best_params_\n",
    "# {'C': 1.2530940677291005, 'penalty': 'l1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = list(range(1,30))\n",
    "leaf_size = list(range(1,50))\n",
    "\n",
    "hyperparameters = dict(n_neighbors = n_neighbors, leaf_size = leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-36-3ef3fe545752>\", line 3, in <module>\n",
      "    best_knn_model = knn_random.fit(X_train, y_train)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 688, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 1469, in _run_search\n",
      "    random_state=self.random_state))\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 667, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 1006, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 834, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 753, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 201, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 582, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 516, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\", line 917, in fit\n",
      "    return self._fit(X)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\", line 257, in _fit\n",
      "    **self.effective_metric_params_)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/sebastianmonzon/anaconda3/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier()\n",
    "knn_random = RandomizedSearchCV(neigh, hyperparameters, cv = cv, random_state = 1, n_iter = 20)\n",
    "best_knn_model = knn_random.fit(X_train, y_train)\n",
    "\n",
    "i = np.where(best_knn_model.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "mean = best_knn_model.cv_results_['mean_test_score'][i]\n",
    "std = best_knn_model.cv_results_['std_test_score'][i]\n",
    "results['KNN'] = [mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'alpha': [0, .5, 1, 1.5, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb_gridsearch = GridSearchCV(mnb, hyperparameters, cv=cv)\n",
    "best_mnb_model = mnb_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "i = np.where(best_mnb_model.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "mean = best_mnb_model.cv_results_['mean_test_score'][i]\n",
    "std = best_mnb_model.cv_results_['std_test_score'][i]\n",
    "results['MNB'] = [mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "criteria = ['entropy', 'gini']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "hyperparameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'criterion': criteria,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(rf, hyperparameters, cv = cv, random_state = 1, n_iter = 50)\n",
    "best_rf_model = rf_random.fit(X_train, y_train)\n",
    "\n",
    "i = np.where(best_rf_model.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "mean = best_rf_model.cv_results_['mean_test_score'][i]\n",
    "std = best_rf_model.cv_results_['std_test_score'][i]\n",
    "results['Random Forest'] = [mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_range = np.random.uniform(0.0, 0.3, 5).astype(float)\n",
    "C_range = np.random.normal(1, 0.1, 5).astype(float)\n",
    " \n",
    "C_range[C_range < 0] = 0.0001\n",
    " \n",
    "hyperparameters = {'gamma': list(g_range), \n",
    "                    'C': list(C_range)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svm = svm.LinearSVC()\n",
    "randomSVM = RandomizedSearchCV(lin_svm(kernel='rbf',), hyperparameters, n_iter = 20)\n",
    "best_SVM_model = randomSVM.fit(XTrain, yTrain)\n",
    "\n",
    "i = np.where(best_SVM_model.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "mean = best_SVM_model.cv_results_['mean_test_score'][i]\n",
    "std = best_SVM_model.cv_results_['std_test_score'][i]\n",
    "results['Linear SVM'] = [mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Results and Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline Logistic Regression': [0.5662650602409639, nan],\n",
       " 'Baseline Random Forest': [0.5737951807228916, nan],\n",
       " 'Logistic Regression': [0.6608063049408912, 0.025842013597734977]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient = 'index', columns = ['Accuracy', 'Standard_Deviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Standard_Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.660806</td>\n",
       "      <td>0.025842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest</th>\n",
       "      <td>0.573795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression</th>\n",
       "      <td>0.566265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy  Standard_Deviation\n",
       "Logistic Regression           0.660806            0.025842\n",
       "Baseline Random Forest        0.573795                 NaN\n",
       "Baseline Logistic Regression  0.566265                 NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = ['Accuracy'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion= pd.DataFrame(confusion_matrix(y_test, chosen_model.fit(X_train, y_train).predict(X_test)))\n",
    "confusion.columns = ['pred class ' + str(x) for x in list(range(1,10))]\n",
    "confusion.index = ['true class ' + str(x) for x in list(range(1,10))]\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
